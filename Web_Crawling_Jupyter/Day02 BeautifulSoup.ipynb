{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa18fed4",
   "metadata": {},
   "source": [
    "# BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d9505",
   "metadata": {},
   "source": [
    "- find - 태그로 < > 값을 찾는"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"title\").string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd406c",
   "metadata": {},
   "source": [
    "- select - css 속성으로 값을 찾는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e160854",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"title\")\n",
    "soup.select_one(\"title\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ee173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3d19b0b",
   "metadata": {},
   "source": [
    "### 1. find 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e624169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 =  스크레이핑이란?\n",
      "p1 =  웹 페이지를 분석하는 것\n",
      "p2 =  원하는부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <h1>스크레이핑이란?</h1>\n",
    "    <p>웹 페이지를 분석하는 것</p>\n",
    "    <p>원하는부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "print(\"h1 = \", h1.string)\n",
    "print(\"p1 = \", p1.string)\n",
    "print(\"p2 = \", p2.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0b918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title =  스크레이핑이란?\n",
      "body =  웹 페이지를 분석하는 것\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <h1 id=\"title\">스크레이핑이란?</h1>\n",
    "    <p id=\"body\">웹 페이지를 분석하는 것</p>\n",
    "    <p>원하는부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "title = soup.find(id=\"title\")\n",
    "body = soup.find(id=\"body\")\n",
    "\n",
    "print(\"title = \", title.string)\n",
    "print(\"body = \", body.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ffd53ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver > http://www.naver.com\n",
      "daum > http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <ul>\n",
    "        <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "        <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "    </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "for i in links:\n",
    "    href = i.attrs['href']\n",
    "    text = i.string\n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb976807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9380637",
   "metadata": {},
   "source": [
    "### XML 태그 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b3ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기상청 육상 중기예보\n",
      "○ (하늘상태) 이번 예보기간에는 전국이 구름많거나 흐린 날이 많겠습니다.<br />○ (기온) 이번 예보기간 아침 기온은 17~23도, 낮 기온은 25~31도로 평년(최저기온 18~21도, 최고기온 25~29도)과 비슷하거나 조금 높겠습니다.<br />○ (주말전망) 24일(토)~25일(일)은 전국이 구름많겠습니다. 아침 기온은 19~22도, 낮 기온은 26~31도가 되겠습니다.<br /><br />* 제주도남쪽먼해상에 위치한 정체전선이 25일(일) 이후 점차 북상할 가능성이 있어 예보 변동성이 크겠으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=108\"\n",
    "\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "title = soup.find(\"title\").string\n",
    "wf = soup.find(\"wf\").string\n",
    "\n",
    "print(title)\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3beb2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a9c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9068e39",
   "metadata": {},
   "source": [
    "- 실습 1) 시 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e9e1709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/wiki/%EA%B0%80%EB%8A%94_%EB%B4%84_%EC%82%BC%EC%9B%94\" title=\"가는 봄 삼월\">가는 봄 삼월</a>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EA%B9%80%EC%86%8C%EC%9B%94\"\n",
    "\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")    # 결과 텍스트(res.text)를 html.parser로 파싱 -> html 태그 형식으로 객체 생성\n",
    "\n",
    "a = soup.select(\".mw-parser-output > ul:nth-child(9) > li\")\n",
    "\n",
    "for i in a:\n",
    "    print(\"-\", i.text)\n",
    "\n",
    "# for i in range(35):\n",
    "#     print(\"-\", soup.select_one(f\"ul:nth-child(9) > li:nth-child({i+1})\").text)\n",
    "\n",
    "# for i in soup.select(\"div.mw-parser-output > ul\")[1:-2]:\n",
    "#     print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbcb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa23723f",
   "metadata": {},
   "source": [
    "- 실습2) 로또 번호 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "076fb579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072회\n",
      "당첨번호 1:  16\n",
      "당첨번호 2:  18\n",
      "당첨번호 3:  20\n",
      "당첨번호 4:  23\n",
      "당첨번호 5:  32\n",
      "당첨번호 6:  43\n",
      "보너스 번호 :  27\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://www.dhlottery.co.kr/gameResult.do?method=byWin&wiselog=H_C_1_1\"\n",
    "\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "\n",
    "num = soup.select(\"span.ball_645\")\n",
    "for i in range(7):\n",
    "    if i == 0:\n",
    "        print(soup.select_one(\"div.win_result > h4 > strong\").text)\n",
    "        print(f\"당첨번호 {i+1}:  {num[i].text}\")\n",
    "    elif i < 6:\n",
    "        print(f\"당첨번호 {i+1}:  {num[i].text}\")\n",
    "    else:\n",
    "        print(f\"보너스 번호 : \", num[i].text)\n",
    "\n",
    "\n",
    "# for i, j in enumerate(soup.select(\"div.num.win > p > span\"), start=1):\n",
    "#     if i == 1:\n",
    "#         print(soup.select_one(\"div.win_result > h4 > strong\").text)\n",
    "#         print(f\"당첨번호 {i}: \", j.text)\n",
    "#     elif i == 6:\n",
    "#         print(f\"당첨번호 {i}: \", j.text)\n",
    "#         print(\"Bonus : \", soup.select_one(\"div.num.bonus > p > span\").text)\n",
    "#     else:\n",
    "#         print(f\"당첨번호 {i}: \", j.text)\n",
    "\n",
    "\n",
    "# j = 1\n",
    "# for i in range(7):\n",
    "#     if i == 0:\n",
    "#         print(soup.select_one(\"div.win_result > h4 > strong\").text)\n",
    "#         print(\"당첨번호\", j, \":\", soup.select_one(f'div.num.win > p > span:nth-child({j})').text) \n",
    "#     elif i <= 5:\n",
    "#         print(\"당첨번호\", j, \":\", soup.select_one(f'div.num.win > p > span:nth-child({j})').text) \n",
    "#     else:\n",
    "#         print(\"Bonus : \", soup.select_one(\"div.num.bonus > p > span\").text)\n",
    "#     j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b2ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96d5a8d2",
   "metadata": {},
   "source": [
    "- 실습3) 이메일 주소 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3ebddd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hong123@naver.com\n",
      "hellboy2001@gmail.com\n",
      "hi_he1111@yahoo.co.kr\n",
      "hacker97@gmail.com\n",
      "qwer8804@daum.net\n",
      "a_b_c_market@naver.com\n",
      "hong1234@naver.com\n",
      "daebak777@naver.com\n",
      "alienaaaa1@gmail.com\n",
      "zxcv1234@daum.net\n",
      "wtf333@gmail.com\n",
      "kkk_hhh_hi@naver.com\n",
      "elfot321@daum.net\n",
      "geqfadf_123ca@naver.com\n",
      "h1h1h1h1@gmail.com\n",
      "crazytrol12@naver.com\n",
      "chungju_jjang@gmail.com\n",
      "jjja4444@naver.com\n",
      "powers1211@gmail.com\n",
      "voiceheaven94@naver.com\n",
      "artist78@naver.com\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'http://localhost/surveyinfo.html'\n",
    "\n",
    "res = requests.get(url)\n",
    "res.encoding=\"utf-8\"\n",
    "\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "for i in range(21):\n",
    "    print(soup.select_one(f\"tbody > tr:nth-child({i+1}) > td:nth-child(4)\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f9addf37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hong123@naver.com\n",
      "hellboy2001@gmail.com\n",
      "hacker97@gmail.com\n",
      "qwer8804@daum.net\n",
      "a_b_c_market@naver.com\n",
      "hong1234@naver.com\n",
      "daebak777@naver.com\n",
      "alienaaaa1@gmail.com\n",
      "zxcv1234@daum.net\n",
      "wtf333@gmail.com\n",
      "kkk_hhh_hi@naver.com\n",
      "elfot321@daum.net\n",
      "geqfadf_123ca@naver.com\n",
      "h1h1h1h1@gmail.com\n",
      "crazytrol12@naver.com\n",
      "chungju_jjang@gmail.com\n",
      "jjja4444@naver.com\n",
      "powers1211@gmail.com\n",
      "voiceheaven94@naver.com\n",
      "artist78@naver.com\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "url = \"http://localhost/surveyinfo.html\" \n",
    "data = urlopen(url).read().decode(\"utf8\")\n",
    "\n",
    "matches = re.findall(r\"([a-zA-Z0-9._+]+@[a-zA-Z0-9]+\\.(com|org|net))\", data)\n",
    "\n",
    "for i in matches:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4f85b4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hong123@naver.com\n",
      "hellboy2001@gmail.com\n",
      "hi_he1111@yahoo.co.kr\n",
      "hacker97@gmail.com\n",
      "qwer8804@daum.net\n",
      "a_b_c_market@naver.com\n",
      "hong1234@naver.com\n",
      "daebak777@naver.com\n",
      "alienaaaa1@gmail.com\n",
      "zxcv1234@daum.net\n",
      "wtf333@gmail.com\n",
      "kkk_hhh_hi@naver.com\n",
      "elfot321@daum.net\n",
      "geqfadf_123ca@naver.com\n",
      "h1h1h1h1@gmail.com\n",
      "crazytrol12@naver.com\n",
      "chungju_jjang@gmail.com\n",
      "jjja4444@naver.com\n",
      "powers1211@gmail.com\n",
      "voiceheaven94@naver.com\n",
      "artist78@naver.com\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re       # 정규표현식 모듈\n",
    "\n",
    "url = \"http://localhost/surveyinfo.html\"\n",
    "\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "td_list = soup.find_all('td')\n",
    "\n",
    "email_re = r\"[a-zA-Z0-9._+]+@[a-zA-Z0-9]+(\\.[A-Za-z]{2,3}|)\\.[A-Za-z]{2,3}\"  \n",
    "\n",
    "# [a-zA-Z0-9._+]+@[a-zA-Z0-9]+(\\.[A-Za-z]{2}){0,1}\\.[A-Za-z]{2,3}\n",
    "# [a-zA-Z0-9._+]+@[a-zA-Z0-9]+\\.((com|org|net)|(co\\.kr))            yahoo.co.kr 포함하는 정규표현식\n",
    "# 점(.) 은 아무 문자 하나를 의미함   점(.) 사용 시 \\. 함께 사용 (점 이라는 문자가 있음을 의미)\n",
    "\n",
    "pattern = re.compile(email_re)\n",
    "\n",
    "for td in td_list:\n",
    "    match = pattern.search(td.get_text())\n",
    "    if match != None:\n",
    "        print(match.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1de61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28b1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "004caa85",
   "metadata": {},
   "source": [
    "- 정규 표현식 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "aa57b522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://example.com\n",
      "https://wahu.com\n",
      "https://yeap.com\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = \"\"\"\n",
    "<ul>\n",
    "    <li><a href=\"https://example.com\"</li>\n",
    "    <li><a href=\"http://example.com\"</li>\n",
    "    <li><a href=\"https://wahu.com\"</li>\n",
    "    <li><a href=\"https://yeap.com\"</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "\n",
    "li = soup.find_all(href=re.compile(r\"(^https://)\"))\n",
    "\n",
    "for e in li:\n",
    "    print(e.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc96f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5064a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2c3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac4e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18ba4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f8a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91907269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac2e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f61b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221e882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
